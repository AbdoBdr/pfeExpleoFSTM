# -*- coding: utf-8 -*-
"""Untitled15.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RURT-XyKFKjF6IOOVyxZ0E9LSC0v3u6c
"""

import numpy as np
import matplotlib.pyplot as plt
import random
import os
import PIL
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from skimage.transform import resize
from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_fscore_support
import seaborn as sns
import tensorflow as tf

# Vérifier si TPU est disponible
tpu_available = False
try:
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # Détecter TPU
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.experimental.TPUStrategy(tpu)
    tpu_available = True
    print("Utilisation de TPU")
except Exception as e:
    print("TPU non disponible :", str(e))
    strategy = tf.distribute.get_strategy()  # Stratégie par défaut

# Emplacement du jeu de données
DATASET_PATH = "/content/drive/MyDrive/Object_Detection_Classification_-_Ford_Otosan_Intern_P2-master/src/datapfe14juinug"

# Charger les images en tant que tableaux Numpy
labels = []
y_all = []
X_all = []

# Nombre d'images à importer par classe
num_images_per_class = 1500

for label in os.listdir(DATASET_PATH):
    class_dir = os.path.join(DATASET_PATH, label)
    if os.path.isdir(class_dir) and label != ".ipynb_checkpoints":
        labels.append(label)
        image_count = 0
        for i, file in enumerate(os.listdir(class_dir)):
            if file != ".ipynb_checkpoints" and image_count < num_images_per_class:
                file_path = os.path.join(class_dir, file)
                img = PIL.Image.open(file_path).convert('L')
                img_array = np.asarray(img)
                X_all.append(img_array)
                y_all.append(label)
                image_count += 1
        print("Ajout de", image_count, "images de", label)

# Convertir les étiquettes en nombres
y_out = [labels.index(label) for label in y_all]
y_all = y_out

# Mélanger les échantillons et les étiquettes ensemble, utiliser l'ensemble de données entier pour l'entraînement
X_y = list(zip(X_all, y_all))
random.shuffle(X_y)
X_all, y_all = zip(*X_y)
X_train = X_all
y_train = y_all
num_samples_train = len(X_train)
print("Nombre d'échantillons d'entraînement:", num_samples_train)

# Redimensionner les images avec antialiasing
TARGET_WIDTH = 250
TARGET_HEIGHT = 250
X_train_resized = [resize(image, (TARGET_WIDTH, TARGET_HEIGHT), anti_aliasing=True) for image in X_train]

# Convertir la liste des échantillons et des étiquettes en tableaux Numpy
X_train_resized = np.array(X_train_resized)
X_train_resized = X_train_resized.reshape((-1, TARGET_WIDTH, TARGET_HEIGHT, 1))
num_classes = len(labels)
y_train_onehot = to_categorical(y_train, num_classes)

# Diviser les données en ensembles d'entraînement et de validation
X_train_resized, X_val_resized, y_train_onehot, y_val_onehot = train_test_split(X_train_resized, y_train_onehot, test_size=0.2, random_state=42)

# Construction du modèle CNN
with strategy.scope(): # utiliser la stratégie TPU
    model = Sequential()
    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(TARGET_WIDTH, TARGET_HEIGHT, 1)))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Flatten())
    model.add(Dense(128, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(num_classes, activation='softmax'))
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    print(model.summary())

# Entraîner le modèle
history = model.fit(X_train_resized, y_train_onehot,
                    batch_size=32,
                    epochs=30,
                    verbose=1,
                    validation_data=(X_val_resized, y_val_onehot))

# Tracer l'exactitude et la perte d'entraînement au fil du temps
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(acc) + 1)

plt.figure()
plt.plot(epochs, loss, color='blue', marker='.', label='Perte d\'entraînement')
plt.plot(epochs, val_loss, color='red', marker='.', label='Perte de validation')
plt.title('Perte d\'entraînement et de validation')
plt.xlabel('Époques')
plt.ylabel('Perte')
plt.legend()

plt.figure()
plt.plot(epochs, acc, color='blue', marker='.', label='Précision d\'entraînement')
plt.plot(epochs, val_acc, color='red', marker='.', label='Précision de validation')
plt.title('Précision d\'entraînement et de validation')
plt.xlabel('Époques')
plt.ylabel('Précision')
plt.legend()
plt.show()

# Sauvegarder le modèle
model.save("/content/drive/MyDrive/weatherclass2/modele30mai_adam.h5")

# Courbe ROC et AUC pour chaque classe
y_pred_proba = model.predict(X_val_resized)

plt.figure()
for i in range(num_classes):
    fpr, tpr, _ = roc_curve(y_val_onehot[:, i], y_pred_proba[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, lw=2, label='Classe {} (AUC = {:0.2f})'.format(labels[i], roc_auc))

plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taux de faux positifs')
plt.ylabel('Taux de vrais positifs')
plt.title('Courbes ROC pour chaque classe')
plt.legend(loc="lower right")
plt.show()

# Matrice de confusion
y_pred = np.argmax(model.predict(X_val_resized), axis=1)
cm = confusion_matrix(np.argmax(y_val_onehot, axis=1), y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=labels, yticklabels=labels)
plt.xlabel('Classe prédite')
plt.ylabel('Classe réelle')
plt.title('Matrice de confusion')
plt.show()

# Précision, Rappel et F1-score
precision, recall, fscore, _ = precision_recall_fscore_support(np.argmax(y_val_onehot, axis=1), y_pred, average='weighted')
print("Précision : {:.2f}".format(precision))
print("Rappel : {:.2f}".format(recall))
print("F1-score : {:.2f}".format(fscore))

import numpy as np
import matplotlib.pyplot as plt
import random
import os
import PIL
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from skimage.transform import resize
from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_fscore_support
import seaborn as sns
import tensorflow as tf
from keras.callbacks import EarlyStopping

# Vérifier si TPU est disponible
tpu_available = False
try:
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # Détecter TPU
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.experimental.TPUStrategy(tpu)
    tpu_available = True
    print("Utilisation de TPU")
except Exception as e:
    print("TPU non disponible :", str(e))
    strategy = tf.distribute.get_strategy()  # Stratégie par défaut

# Emplacement du jeu de données
DATASET_PATH = "/content/drive/MyDrive/Object_Detection_Classification_-_Ford_Otosan_Intern_P2-master/src/datapfe14juinug"

# Charger les images en tant que tableaux Numpy
labels = []
y_all = []
X_all = []

# Nombre d'images à importer par classe
num_images_per_class = 1500

for label in os.listdir(DATASET_PATH):
    class_dir = os.path.join(DATASET_PATH, label)
    if os.path.isdir(class_dir) and label != ".ipynb_checkpoints":
        labels.append(label)
        image_count = 0
        for i, file in enumerate(os.listdir(class_dir)):
            if file != ".ipynb_checkpoints" and image_count < num_images_per_class:
                file_path = os.path.join(class_dir, file)
                img = PIL.Image.open(file_path).convert('L')
                img_array = np.asarray(img)
                X_all.append(img_array)
                y_all.append(label)
                image_count += 1
        print("Ajout de", image_count, "images de", label)

# Convertir les étiquettes en nombres
y_out = [labels.index(label) for label in y_all]
y_all = y_out

# Mélanger les échantillons et les étiquettes ensemble, utiliser l'ensemble de données entier pour l'entraînement
X_y = list(zip(X_all, y_all))
random.shuffle(X_y)
X_all, y_all = zip(*X_y)
X_train = X_all
y_train = y_all
num_samples_train = len(X_train)
print("Nombre d'échantillons d'entraînement:", num_samples_train)

# Redimensionner les images avec antialiasing
TARGET_WIDTH = 250
TARGET_HEIGHT = 250
X_train_resized = [resize(image, (TARGET_WIDTH, TARGET_HEIGHT), anti_aliasing=True) for image in X_train]

# Convertir la liste des échantillons et des étiquettes en tableaux Numpy
X_train_resized = np.array(X_train_resized)
X_train_resized = X_train_resized.reshape((-1, TARGET_WIDTH, TARGET_HEIGHT, 1))
num_classes = len(labels)
y_train_onehot = to_categorical(y_train, num_classes)

# Diviser les données en ensembles d'entraînement et de validation
X_train_resized, X_val_resized, y_train_onehot, y_val_onehot = train_test_split(X_train_resized, y_train_onehot, test_size=0.2, random_state=42)

# Construction du modèle CNN
with strategy.scope(): # utiliser la stratégie TPU
    model = Sequential()
    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(TARGET_WIDTH, TARGET_HEIGHT, 1)))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Flatten())
    model.add(Dense(128, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(num_classes, activation='softmax'))
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    print(model.summary())

# Définir l'early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Entraîner le modèle
history = model.fit(X_train_resized, y_train_onehot,
                    batch_size=32,
                    epochs=30,
                    verbose=1,
                    validation_data=(X_val_resized, y_val_onehot),
                    callbacks=[early_stopping])

# Tracer l'exactitude et la perte d'entraînement au fil du temps
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(acc) + 1)

plt.figure()
plt.plot(epochs, loss, color='blue', marker='.', label='Perte d\'entraînement')
plt.plot(epochs, val_loss, color='red', marker='.', label='Perte de validation')
plt.title('Perte d\'entraînement et de validation')
plt.xlabel('Époques')
plt.ylabel('Perte')
plt.legend()

plt.figure()
plt.plot(epochs, acc, color='blue', marker='.', label='Précision d\'entraînement')
plt.plot(epochs, val_acc, color='red', marker='.', label='Précision de validation')
plt.title('Précision d\'entraînement et de validation')
plt.xlabel('Époques')
plt.ylabel('Précision')
plt.legend()
plt.show()

# Sauvegarder le modèle
model.save("/content/drive/MyDrive/weatherclass2/modele30june_adam.h5")

# Courbe ROC et AUC pour chaque classe
y_pred_proba = model.predict(X_val_resized)

plt.figure()
for i in range(num_classes):
    fpr, tpr, _ = roc_curve(y_val_onehot[:, i], y_pred_proba[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, lw=2, label='Classe {} (AUC = {:0.2f})'.format(labels[i], roc_auc))

plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taux de faux positifs')
plt.ylabel('Taux de vrais positifs')
plt.title('Courbes ROC pour chaque classe')
plt.legend(loc="lower right")
plt.show()

# Matrice de confusion
y_pred = np.argmax(model.predict(X_val_resized), axis=1)
cm = confusion_matrix(np.argmax(y_val_onehot, axis=1), y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=labels, yticklabels=labels)
plt.xlabel('Classe prédite')
plt.ylabel('Classe réelle')
plt.title('Matrice de confusion')
plt.show()

# Précision, Rappel et F1-score
precision, recall, fscore, _ = precision_recall_fscore_support(np.argmax(y_val_onehot, axis=1), y_pred, average='weighted')
print("Précision : {:.2f}".format(precision))
print("Rappel : {:.2f}".format(recall))
print("F1-score : {:.2f}".format(fscore))